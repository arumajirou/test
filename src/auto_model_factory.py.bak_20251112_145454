# src/auto_model_factory.py
from __future__ import annotations

from typing import Dict, Any, Optional, List, Callable
from dataclasses import dataclass, field
import logging
import time
from datetime import datetime
import json

import pandas as pd
import numpy as np

# project-local
from .validation import (
    ConfigValidator,
    DataValidator,
    validate_all,
    print_validation_results,
)
from .search_algorithm_selector import (
    SearchAlgorithmSelector,
    ModelComplexity,
    DatasetSize,
    SearchComplexity,
    recommend_num_samples,
)

logger = logging.getLogger(__name__)

# -----------------------------------------------------------------------------
# Helper: instantiate Auto* model while filtering out unknown kwargs
# -----------------------------------------------------------------------------
def _instantiate_model(AutoModelClass, *args, **kwargs):
    import inspect
    sig = inspect.signature(AutoModelClass.__init__)
    allowed = {k: v for k, v in kwargs.items() if k in sig.parameters}
    return AutoModelClass(*args, **allowed)


@dataclass
class ModelCharacteristics:
    name: str
    complexity: ModelComplexity
    recommended_input_size_range: tuple = (7, 24)
    supports_exogenous: bool = True
    supports_static: bool = False
    typical_training_time_minutes: float = 10.0
    memory_footprint_mb: float = 500.0
    default_config: Dict[str, Any] = field(default_factory=dict)

    def __repr__(self):
        return f"ModelCharacteristics(name={self.name}, complexity={self.complexity.value})"


MODEL_CATALOG = {
    "MLP": ModelCharacteristics(
        name="MLP",
        complexity=ModelComplexity.SIMPLE,
        recommended_input_size_range=(7, 14),
        typical_training_time_minutes=5.0,
        memory_footprint_mb=300.0,
    ),
    "NHITS": ModelCharacteristics(
        name="NHITS",
        complexity=ModelComplexity.MODERATE,
        recommended_input_size_range=(14, 28),
        typical_training_time_minutes=10.0,
        memory_footprint_mb=800.0,
    ),
    "NBEATS": ModelCharacteristics(
        name="NBEATS",
        complexity=ModelComplexity.MODERATE,
        recommended_input_size_range=(14, 28),
        typical_training_time_minutes=10.0,
        memory_footprint_mb=800.0,
    ),
    "DLinear": ModelCharacteristics(
        name="DLinear",
        complexity=ModelComplexity.MODERATE,
        recommended_input_size_range=(24, 96),
        typical_training_time_minutes=8.0,
        memory_footprint_mb=400.0,
    ),
    "TSMixer": ModelCharacteristics(
        name="TSMixer",
        complexity=ModelComplexity.MODERATE,
        recommended_input_size_range=(24, 96),
        supports_static=True,
        typical_training_time_minutes=15.0,
        memory_footprint_mb=1000.0,
    ),
    "TFT": ModelCharacteristics(
        name="TFT",
        complexity=ModelComplexity.COMPLEX,
        recommended_input_size_range=(24, 168),
        supports_static=True,
        typical_training_time_minutes=30.0,
        memory_footprint_mb=2000.0,
    ),
    "Transformer": ModelCharacteristics(
        name="Transformer",
        complexity=ModelComplexity.COMPLEX,
        recommended_input_size_range=(24, 96),
        typical_training_time_minutes=25.0,
        memory_footprint_mb=1500.0,
    ),
    "PatchTST": ModelCharacteristics(
        name="PatchTST",
        complexity=ModelComplexity.COMPLEX,
        recommended_input_size_range=(96, 512),
        typical_training_time_minutes=20.0,
        memory_footprint_mb=1200.0,
    ),
}


@dataclass
class OptimizationConfig:
    backend: str = "optuna"
    num_samples: Optional[int] = None
    cpus: int = 4
    gpus: int = 0

    validation_split: float = 0.2
    test_split: float = 0.1

    use_mlflow: bool = True
    mlflow_tracking_uri: Optional[str] = None
    mlflow_experiment_name: Optional[str] = None

    use_pruning: bool = True
    random_seed: Optional[int] = 42
    time_budget_hours: Optional[float] = None

    verbose: bool = True
    callbacks: Optional[List[Callable]] = None

    strict_validation: bool = False
    auto_correct: bool = True


class AutoModelFactory:
    def __init__(
        self,
        model_name: str,
        h: int,
        optimization_config: Optional[OptimizationConfig] = None,
    ):
        self.model_name = model_name
        self.h = h
        self.config = optimization_config or OptimizationConfig()

        if model_name not in MODEL_CATALOG:
            logger.warning(f"Model '{model_name}' not in catalog. Using default characteristics.")
            self.model_char = ModelCharacteristics(name=model_name, complexity=ModelComplexity.MODERATE)
        else:
            self.model_char = MODEL_CATALOG[model_name]

        self.config_validator = ConfigValidator(strict_mode=self.config.strict_validation)
        self.data_validator = DataValidator()
        self.algorithm_selector = SearchAlgorithmSelector(backend=self.config.backend)

        if self.config.use_mlflow:
            self._setup_mlflow()

        self.optimization_history: List[Dict[str, Any]] = []

    def _setup_mlflow(self):
        """Lightweight, version-tolerant MLflow setup (no use of deprecated/private APIs)."""
        try:
            import mlflow

            if self.config.mlflow_tracking_uri:
                mlflow.set_tracking_uri(self.config.mlflow_tracking_uri)

            exp_name = (
                self.config.mlflow_experiment_name
                or f"neuralforecast_{self.model_name}_{datetime.now().strftime('%Y%m%d')}"
            )
            mlflow.set_experiment(exp_name)

            logger.info(f"MLflow tracking URI: {mlflow.get_tracking_uri()}")
            logger.info(f"MLflow experiment set: {exp_name}")
        except Exception as e:
            logger.error(f"Failed to setup MLflow: {e}")
            self.config.use_mlflow = False

    # ------------------------------------------------------------------
    # Public entry
    # ------------------------------------------------------------------
    def create_auto_model(
        self,
        dataset: pd.DataFrame,
        config: Optional[Dict[str, Any]] = None,
        loss: Optional[Any] = None,
        valid_loss: Optional[Any] = None,
        **kwargs,
    ):
        start_time = time.time()

        # 1) Validation
        validation_results = self._validate_configuration(dataset=dataset, config=config or {})
        if self.config.verbose:
            print_validation_results(validation_results)

        # 2) Dataset analysis
        dataset_info = self._analyze_dataset(dataset)

        # 3) Strategy selection
        search_strategy = self._select_search_strategy(dataset_info=dataset_info, config=config or {})

        # 4) Hyperparameter config
        final_config = self._prepare_config(config, dataset_info)

        # 5) Create & optimize
        auto_model = self._create_and_optimize(
            dataset=dataset,
            config=final_config,
            search_strategy=search_strategy,
            loss=loss,
            valid_loss=valid_loss,
            **kwargs,
        )

        elapsed_time = time.time() - start_time
        self._record_optimization(
            elapsed_time=elapsed_time,
            dataset_info=dataset_info,
            search_strategy=search_strategy,
            final_config=final_config,
        )
        logger.info(f"Optimization completed in {elapsed_time:.2f} seconds")
        return auto_model

    # ------------------------------------------------------------------
    # Internals
    # ------------------------------------------------------------------
    def _validate_configuration(self, dataset: pd.DataFrame, config: Dict[str, Any]) -> Dict[str, Any]:
        return validate_all(
            backend=self.config.backend,
            config=config,
            num_samples=self.config.num_samples or 50,
            cpus=self.config.cpus,
            gpus=self.config.gpus,
            model_class_name=self.model_name,
            dataset=dataset,
            h=self.h,
            mlflow_tracking_uri=self.config.mlflow_tracking_uri,
            mlflow_experiment_name=self.config.mlflow_experiment_name,
            strict_mode=self.config.strict_validation,
        )

    def _analyze_dataset(self, dataset: pd.DataFrame) -> Dict[str, Any]:
        if isinstance(dataset, pd.DataFrame):
            if "unique_id" in dataset.columns:
                try:
                    n_series = int(dataset["unique_id"].nunique())
                    avg_length = float(dataset.groupby("unique_id").size().mean())
                except Exception:
                    n_series = 1
                    avg_length = float(len(dataset))
            else:
                n_series = 1
                avg_length = float(len(dataset))
            n_observations = int(len(dataset))
            has_exog = any(col not in ["unique_id", "ds", "y"] for col in dataset.columns)
        else:
            n_series = 1
            n_observations = int(len(dataset))
            avg_length = float(n_observations)
            has_exog = False

        if n_observations < 1000:
            dataset_size = DatasetSize.SMALL
        elif n_observations < 100000:
            dataset_size = DatasetSize.MEDIUM
        else:
            dataset_size = DatasetSize.LARGE

        info = {
            "n_series": n_series,
            "n_observations": n_observations,
            "avg_length": avg_length,
            "dataset_size": dataset_size,
            "has_exog": has_exog,
            "columns": list(dataset.columns) if isinstance(dataset, pd.DataFrame) else [],
        }

        logger.info("Dataset info: "
                    f"Series={n_series}, Observations={n_observations}, "
                    f"AvgLen={avg_length:.1f}, Size={dataset_size.value}, HasExog={has_exog}")
        return info

    def _select_search_strategy(self, dataset_info: Dict[str, Any], config: Dict[str, Any]):
        if self.config.num_samples is None:
            recommended, explanation = recommend_num_samples(
                model_complexity=self.model_char.complexity,
                dataset_size=dataset_info["dataset_size"],
                search_complexity=SearchComplexity.MEDIUM,
                time_budget_hours=self.config.time_budget_hours,
            )
            self.config.num_samples = recommended
            logger.info(f"Auto-selected num_samples: {explanation}")

        strategy = self.algorithm_selector.select_algorithm(
            model_complexity=self.model_char.complexity,
            dataset_size=dataset_info["dataset_size"],
            num_samples=self.config.num_samples,
            config=config,
            use_pruning=self.config.use_pruning,
            random_seed=self.config.random_seed,
        )
        logger.info(f"Selected search strategy: {strategy}")
        return strategy

    def _prepare_config(
        self,
        config: Optional[Dict[str, Any]],
        dataset_info: Dict[str, Any],
    ) -> Any:
        """Return a config object compatible with the selected backend.
        - For Optuna: Callable[[trial], Dict[str, Any]]
        - For Ray: a dict/tune search space is acceptable
        """
        if config is not None:
            return config

        # Defaults by model
        min_input, max_input = self.model_char.recommended_input_size_range
        avg_length = dataset_info["avg_length"]
        input_size_options = []
        if avg_length < min_input:
            input_size_options = [max(2, int(avg_length * 0.5)), max(2, int(avg_length * 0.7))]
        else:
            for size in [min_input, (min_input + max_input) // 2, max_input]:
                if size < avg_length:
                    input_size_options.append(size)
        if not input_size_options:
            input_size_options = [max(2, int(max(4, avg_length // 2)))]

        if self.config.backend == "optuna":
            import optuna  # noqa: F401

            def config_fn(trial):
                cfg = {
                    "max_steps": trial.suggest_categorical("max_steps", [500, 1000, 2000]),
                    "learning_rate": trial.suggest_float("learning_rate", 1e-4, 1e-2, log=True),
                    "batch_size": trial.suggest_categorical("batch_size", [32, 64, 128, 256]),
                    "val_check_steps": trial.suggest_categorical("val_check_steps", [50, 100, 200]),
                    "early_stop_patience_steps": trial.suggest_categorical("early_stop_patience_steps", [2, 3, 5]),
                    "input_size": trial.suggest_categorical("input_size", input_size_options),
                }
                if self.model_name in ["NHITS", "NBEATS"]:
                    cfg["n_blocks"] = trial.suggest_categorical("n_blocks", [(1, 1, 1), (2, 2, 2), (3, 3, 3)])
                    cfg["mlp_units"] = trial.suggest_categorical("mlp_units", [(512, 512), (256, 256), (128, 128)])
                elif self.model_name == "TFT":
                    cfg["hidden_size"] = trial.suggest_categorical("hidden_size", [64, 128, 256])
                    cfg["dropout"] = trial.suggest_float("dropout", 0.1, 0.3)
                    cfg["num_attention_heads"] = trial.suggest_categorical("num_attention_heads", [2, 4, 8])
                elif self.model_name == "Transformer":
                    cfg["n_head"] = trial.suggest_categorical("n_head", [2, 4, 8])
                    cfg["hidden_size"] = trial.suggest_categorical("hidden_size", [64, 128, 256])
                    cfg["dropout"] = trial.suggest_float("dropout", 0.1, 0.3)
                return cfg

            return config_fn
        else:
            # Ray/tune-style space (kept minimal)
            try:
                from ray import tune  # noqa: F401

                cfg = {
                    "max_steps": tune.choice([500, 1000, 2000]),
                    "learning_rate": tune.loguniform(1e-4, 1e-2),
                    "batch_size": tune.choice([32, 64, 128, 256]),
                    "val_check_steps": tune.choice([50, 100, 200]),
                    "early_stop_patience_steps": tune.choice([2, 3, 5]),
                    "input_size": tune.choice(input_size_options),
                }
                if self.model_name in ["NHITS", "NBEATS"]:
                    cfg["n_blocks"] = tune.choice([(1, 1, 1), (2, 2, 2), (3, 3, 3)])
                    cfg["mlp_units"] = tune.choice([(512, 512), (256, 256), (128, 128)])
                elif self.model_name == "TFT":
                    cfg["hidden_size"] = tune.choice([64, 128, 256])
                    cfg["dropout"] = tune.uniform(0.1, 0.3)
                    cfg["num_attention_heads"] = tune.choice([2, 4, 8])
                elif self.model_name == "Transformer":
                    cfg["n_head"] = tune.choice([2, 4, 8])
                    cfg["hidden_size"] = tune.choice([64, 128, 256])
                    cfg["dropout"] = tune.uniform(0.1, 0.3)
                return cfg
            except Exception:
                # Fallback to simple fixed config if ray isn't available
                return {
                    "max_steps": 1000,
                    "learning_rate": 1e-3,
                    "batch_size": 64,
                    "val_check_steps": 100,
                    "early_stop_patience_steps": 3,
                    "input_size": input_size_options[0],
                }

    def _create_and_optimize(
        self,
        dataset: pd.DataFrame,
        config: Any,
        search_strategy: Any,
        loss: Optional[Any],
        valid_loss: Optional[Any],
        **kwargs,
    ):
        # Imports
        try:
            from neuralforecast.auto import (
                AutoNHITS,
                AutoNBEATS,
                AutoTFT,
                AutoMLP,
                AutoDLinear,
                AutoTSMixer,
                AutoPatchTST,
                AutoVanillaTransformer,
            )
            from neuralforecast.losses.pytorch import MSE
        except Exception as e:
            logger.error(f"Failed to import NeuralForecast: {e}")
            raise

        auto_model_map = {
            "NHITS": AutoNHITS,
            "NBEATS": AutoNBEATS,
            "TFT": AutoTFT,
            "MLP": AutoMLP,
            "DLinear": AutoDLinear,
            "TSMixer": AutoTSMixer,
            "PatchTST": AutoPatchTST,
            "Transformer": AutoVanillaTransformer,
        }
        AutoModelClass = auto_model_map.get(self.model_name)
        if AutoModelClass is None:
            raise ValueError(f"Auto model not found for {self.model_name}")

        # Ensure losses are set (avoid NF NoneType valid_loss bug)
        default_loss = MSE()
        use_loss = loss or default_loss
        use_valid_loss = valid_loss or use_loss

        # Build kwargs for Auto* safely
        init_kwargs = dict(
            h=self.h,
            backend=self.config.backend,
            config=config,
            loss=use_loss,
            valid_loss=use_valid_loss,
            num_samples=self.config.num_samples,
            cpus=self.config.cpus,
            gpus=self.config.gpus,
            verbose=self.config.verbose,
            callbacks=self.config.callbacks,
        )

        # Only pass search_alg when it's meaningful (e.g., Ray)
        if self.config.backend != "optuna" and search_strategy is not None:
            init_kwargs["search_alg"] = search_strategy

        # No 'n_series' here; we compute it only for logging
        try:
            n_series = int(dataset["unique_id"].nunique()) if isinstance(dataset, pd.DataFrame) and "unique_id" in dataset.columns else 1
        except Exception:
            n_series = 1

        # MLflow run (optional)
        if self.config.use_mlflow:
            import mlflow
            parent = mlflow.active_run()
            with mlflow.start_run(run_name=f"{self.model_name}_auto_optimization", nested=(parent is not None)):
                mlflow.log_params(
                    {
                        "model_name": self.model_name,
                        "h": self.h,
                        "backend": self.config.backend,
                        "num_samples": self.config.num_samples,
                        "n_series": n_series,
                    }
                )
                auto_model = _instantiate_model(AutoModelClass, **init_kwargs)
                logger.info(f"Starting optimization with {self.config.num_samples} trials...")
                auto_model.fit(dataset=dataset)
        else:
            auto_model = _instantiate_model(AutoModelClass, **init_kwargs)
            logger.info(f"Starting optimization with {self.config.num_samples} trials...")
            auto_model.fit(dataset=dataset)

        return auto_model

    def _record_optimization(
        self,
        elapsed_time: float,
        dataset_info: Dict[str, Any],
        search_strategy: Any,
        final_config: Any,
    ):
        record = {
            "timestamp": datetime.now().isoformat(),
            "model_name": self.model_name,
            "elapsed_time_seconds": elapsed_time,
            "dataset_info": dataset_info,
            "search_strategy": str(search_strategy),
            "num_samples": self.config.num_samples,
            "backend": self.config.backend,
        }
        self.optimization_history.append(record)
        if self.config.verbose:
            logger.info("Optimization summary:\n" + json.dumps(record, indent=2, default=str))

    def get_optimization_summary(self) -> pd.DataFrame:
        if not self.optimization_history:
            logger.warning("No optimization history available")
            return pd.DataFrame()
        return pd.DataFrame(self.optimization_history)


# -----------------------------------------------------------------------------
# Top-level convenience function
# -----------------------------------------------------------------------------
def create_auto_model(
    model_name: str,
    h: int,
    dataset: pd.DataFrame,
    backend: str = "optuna",
    num_samples: Optional[int] = None,
    config: Optional[Dict[str, Any]] = None,
    cpus: int = 4,
    gpus: int = 0,
    use_mlflow: bool = True,
    mlflow_experiment_name: Optional[str] = None,
    mlflow_tracking_uri: Optional[str] = None,
    verbose: bool = True,
    **kwargs,
):
    opt_config = OptimizationConfig(
        backend=backend,
        num_samples=num_samples,
        cpus=cpus,
        gpus=gpus,
        use_mlflow=use_mlflow,
        mlflow_experiment_name=mlflow_experiment_name,
        mlflow_tracking_uri=mlflow_tracking_uri,
        verbose=verbose,
    )

    factory = AutoModelFactory(model_name=model_name, h=h, optimization_config=opt_config)
    return factory.create_auto_model(dataset=dataset, config=config, **kwargs)
